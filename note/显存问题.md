# 显存问题

- `.from_pretrained(...)` (在 `init_context` 中): 负责从硬盘读取权重，并将其“逻辑上”关联到 `meta` 设备的模型空壳上，此过程不消耗显存。
- `FSDP(...)` : 负责将这个逻辑上的模型进行物理“实体化”，按分片策略在每个 GPU 上分配显存并填入真实数据，此过程显存开始上升。

---

### 第 1 步：设计蓝图 (The "Shell" / `meta` model)

- `with init_context()`: 你请来一位顶级的建筑师。
- 他拿出了一张巨大的、详细的**设计蓝图** (`actor_module`)。
- 这张蓝图上精确地画出了每一块乐高积木的**形状、颜色和位置**（对应参数的 `shape`, `dtype`）。比如，“在坐标 (10, 20, 5) 的位置，需要一块 2x4 的红色积木”。
- **关键点**：这张蓝图本身只是一张纸，几乎没有重量和体积（不占用内存）。你拥有了完整的城堡结构，但**你手里一块真实的积木都还没有**。这就是“空壳”的真实含义。

---

### 第 2 步：采购与清点积木 (The "Streaming" & "Association")

现在，你问了一个关键问题：“既然有了蓝图（空壳），为什么还要一块一块地读取（采购）积木？”

因为蓝图只是设计，你需要真实的积木来建造。这些真实的积木数据存储在硬盘的`checkpoint`文件里。

`from_pretrained` 在这里的角色，就像一个聪明的采购经理。他面对的是一个装满了成吨积木的仓库（硬盘上的模型文件，比如 140GB）。

#### 他会怎么做？

1.  **分批采购 (一块一块地读取权重分片)**:

    - 他不会愚蠢地让卡车把仓库里**所有**的积木一次性运到你的客厅（CPU RAM）。你的客厅会立刻被撑爆（OOM 内存溢出）。
    - 相反，他会看一眼蓝图，说：“嗯，我们先造城堡的地基部分。” 然后，他只让卡车从仓库里运来**仅仅用于建造地基的那一箱积木**（比如 `pytorch_model-00001-of-00008.bin` 这个分片）。
    - 这箱积木被临时放在你的**门廊**里（一个**临时的、较小的 CPU 内存缓冲区**）。

2.  **清点与贴标签 (什么叫“关联”上真实数据？)**:

    - 采购经理打开门廊里的这一箱积木。他拿出蓝图，一块一块地核对。
    - 他拿起一块红色的 2x4 积木（从硬盘读到 CPU 缓冲区的真实权重张量），然后查阅蓝图，发现它应该属于坐标 (10, 20, 5) 的位置。
    - **“关联”的魔力在这里**：他并**没有**立刻跑去把这块积木砌到最终的城堡上（因为最终的城堡是要建在各个 GPU 上的）。他做的是，在蓝图上坐标 (10, 20, 5) 的那个**虚拟积木标记旁边，贴上一个标签**，上面写着：“这块积木的实体，就是门廊里那块红色的 2x4”。
    - `from_pretrained` 对这一箱（这一个分片）里的所有积木都完成了这个“贴标签”的动作。

3.  **清空门廊，为下一批做准备 (为什么显存/内存不持续增长？)**:
    - 当地基这一箱积木全部“贴好标签”后，采购经理**立刻让卡车把门廊里的这箱积木运走**（释放掉这个 CPU 内存缓冲区）。
    - 然后他再让卡车运来下一箱积木（比如用于建造一楼墙体的 `...-00002-of-00008.bin`），重复上面的“清点与贴标签”过程。

**回答你的问题：**

- **“为什么还要一块块读取？”**
  因为“空壳”蓝图没有实体，必须从硬盘这个“仓库”里把真实的积木（权重）拿出来。分块读取是为了避免一次性把整个仓库搬到你家客厅（CPU RAM），导致内存爆炸。

- **“什么叫‘关联’上了硬盘上真实的数据？”**
  它不是一个物理上的指针。更准确的理解是：`meta` 设备上的“空壳”参数，在 `from_pretrained` 的过程中，被**替换**成了包含真实数据的、位于**临时 CPU 缓冲区**中的张量。但这个过程是流式的，整个模型从未在 CPU 中完整存在过。所以，“关联”更像是一个动态的“贴标签”过程，让蓝图上的每个位置都知道了自己对应的实体是什么。

- **“为什么 GPU 显存几乎没有变化？”**
  因为整个“采购和贴标签”的过程，都发生在 **CPU 的临时内存缓冲区**里。积木箱子只在“门廊”（CPU RAM）里被打开和清点，**根本没有被搬到楼上的各个房间（各个 GPU）里**。所以 GPU 们此时完全不知道发生了什么，它们的显存自然是空闲的。

---

### 总结

执行完 `from_pretrained` 之后，你得到的是一张**被完整贴好标签的蓝图** (`actor_module`)。这张蓝图在逻辑上是完整的，它知道城堡每一个位置应该用哪一块真实的积木。

然后，在下一步 `FSDP(...)` 被调用时，才是真正的“分发施工”阶段。FSDP 会把这张贴好标签的蓝图分发给每个施工队（每个 GPU），每个施工队只看自己负责的部分，然后直接从仓库（或一个中转站）拿到它需要的那几块积木，在自己的工位上（自己的 VRAM）开始建造。

---

您好！这是一个非常深入且关键的问题，它揭示了 PyTorch FSDP 两个版本（或两种 API 风格）在设计哲学上的核心差异。我们来逐一拆解。

### 高层次总结：两种不同的“装修”思路

想象一下你要装修一栋大楼（你的模型）。你有两种方式：

1.  **FSDP (v1, "整体承包"模式)**: 你找来一个总承包商 (`FSDP` 类)。你把整栋大楼的钥匙 (`actor_module`) 和两份核心文件交给他：

    - **装修单元划分图 (`auto_wrap_policy`)**: 这份图纸告诉他，要把每一层楼（比如 `LlamaDecoderLayer`）作为一个独立的装修单元。
    - **材料与工人分配方案 (`sharding_strategy`)**: 这份方案告诉他，对于每个装修单元，如何把材料（参数）和工人（计算）分配到各个施工队（GPUs）中。
    - 你只需要下达一次指令 `FSDP(...)`，总承包商就会接管一切，按照你的图纸和方案，从上到下把整栋楼都安排好。这是一种**声明式、自上而下**的模式。

2.  **FSDP2 (`fully_shard` API, "分包+现场监理"模式)**: 这种模式更精细，也更亲力亲为。
    - **清点所有建材 (`full_state`)**: 首先，你必须在中央仓库（CPU RAM）里，把建造整栋大楼所需的**所有**砖块、钢筋、水泥（参数）都清点出来，形成一个完整的物料清单 (`full_state`)。
    - **现场指定施工队 (`apply_fsdp2`)**: 你亲自（或者派一个监理 `apply_fsdp2`）走进大楼的毛坯房 (`actor_module`)，一层一层地走。每到一层楼，你都对该层的施工队（`module`）下达具体的指令：“你们这一层，按照这份详细的分片方案 (`fsdp_kwargs`) 来施工”，这个动作就是 `fully_shard(module, ...)`。你对所有需要分片的楼层都下达了指令。
    - **按指令分发物料 (`fsdp2_load_full_state_dict`)**: 最后，你让物流部门 (`fsdp2_load_full_state_dict`) 拿着中央仓库的完整物料清单 (`full_state`)，根据你刚才在每一层下达的指令，把对应的砖块和钢筋精确地运送到每一层的每一个施工队（GPU）手中。
    - 这是一种**命令式、由内而外**的模式。

---

#### 1. FSDP (v1) 模式 (`fsdp_strategy == "fsdp"`)

- **`auto_wrap_policy` (装修单元划分图)**:

  - **是什么**：它是一个函数或者一个策略对象，用来告诉 `FSDP` 构造函数：“当你在模型里递归检查时，一旦遇到某个符合条件的模块（例如，它的类名是 `LlamaDecoderLayer`），就不要再往下深入了，把这个模块整体作为一个 FSDP 的基本分片单元。”
  - **为什么需要**：FSDP 需要知道模型应该被“肢解”到什么粒度。是把整个模型当成一块？还是把每一层 Transformer 当成一块？这个策略就是用来定义这个粒度的。

- **`sharding_strategy` (材料分配方案)**:
  - **是什么**：这是一个枚举值（如 `FULL_SHARD`, `HYBRID_SHARD`），它定义了对于一个被 `auto_wrap_policy` 选中的分片单元，它的参数、梯度和优化器状态应该**如何**被分散到所有 GPU 上。`FULL_SHARD` (ZeRO-3) 意味着全部分散。
  - **为什么需要**：它决定了并行的具体方式和显存优化的程度。

#### 2. FSDP2 (`fully_shard`) 模式 (`fsdp_strategy == "fsdp2"`)

- **`full_state = actor_module.state_dict()` (清点所有建材)**:

  - **是什么**：正如我们之前讨论的，它在 **CPU RAM** 中创建了模型所有参数的一个完整、物化的字典。
  - **为什么需要**：这是 FSDP2 加载流程的一个前置步骤。它将模型的“逻辑状态”转变为一个“物理实体”的清单，以便后续函数可以精确地从中抓取数据并分发。

- **`apply_fsdp2(...)` (现场监理，下达指令)**:

  - **是什么**：这个函数（在你提供的代码中是一个自定义的辅助函数）会遍历模型，找到所有应该被分片的子模块（比如 Transformer 层），然后对**每一个**这样的子模块调用 PyTorch 官方的 `fully_shard(module, ...)` 函数。这个调用并**不加载数据**，它只是在模块上“注册”分片配置，相当于给这个模块打上一个“待分片”的标记和配置。
  - **为什么需要**：这是 FSDP2 的核心 API。与 FSDP v1 包装整个模型不同，FSDP2 的设计思想是让你对模型的不同部分**分别应用**分片逻辑，提供了更高的灵活性。

- **`fsdp2_load_full_state_dict(...)` (按指令分发物料)**:
  - **是什么**：这是一个数据加载函数。它接收已经“打好标记”的模型和那个完整的 CPU 参数字典 `full_state`。然后，它会高效地将 `full_state` 中的数据分片，并只把每个 GPU 需要的那一小部分发送过去，完成最终的“上膛”。
  - **为什么需要**：这个函数将“配置分片”和“加载数据”这两个步骤解耦了。`apply_fsdp2` 负责“怎么分”，而 `fsdp2_load_full_state_dict` 负责“把数据按分好的方式填进去”。

---

### 为什么要这么做？（两种模式的差异和演进）

**FSDP (v1) 更简单，但像个黑盒。** 它提供了一个非常直接的、高级的 API。你告诉它规则，它帮你搞定一切。这对于标准 Transformer 模型来说非常方便。

**FSDP2 更灵活，但更繁琐。** 它是 PyTorch 团队在 FSDP v1 的基础上设计的更现代、更底层的 API。它的优势在于：

1.  **细粒度控制**：你可以对模型中不同的部分应用不同的分片策略（虽然在这个代码里 `fsdp_kwargs` 是一样的，但 API 允许你不同）。
2.  **API 解耦**：将模型结构的分片配置 (`fully_shard`) 和数据的加载 (`set_model_state_dict`) 分开，使得逻辑更清晰，也更容易与其他 checkpointing 库（如 `torch.distributed.checkpoint`）集成。
3.  **未来方向**：`fully_shard` 是 PyTorch 官方现在和未来的主流推荐方式，它提供了更多高级功能和优化（比如 `reshard_after_forward`）。
