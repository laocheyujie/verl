# 使用文档

## 使用方式

1. 环境安装
2. `examples/data_preprocess/demo.py`把数据从`json`转换为`parquet`格式
3. 添加新写的奖励脚本`/verl/workers/reward_manager/external.py`
4. `verl/workers/reward_manager/__init__.py`添加新写的类
5. 编辑`examples/grpo_trainer/run_qwen3_8b_llm_external.sh`, `chmod +x ...`
6. `./examples/grpo_trainer/run_qwen3_8b_llm_external.sh`

## 环境安装

### ~~手动安装 (不推荐)~~

```bash
conda create -n verl python=3.11
conda activate verl
pip install -e . -i https://mirrors.aliyun.com/pypi/simple
pip install psutil ninja msgspec vllm tensordict tensorboard nvitop -i https://mirrors.aliyun.com/pypi/simple
pip install flash-attn --no-build-isolation -i https://mirrors.aliyun.com/pypi/simple
# or
# MAX_JOBS=128 pip install flash-attn --no-build-isolation
pip install flashinfer-python
```

### Docker 安装 (推荐)

> - https://verl.readthedocs.io/en/latest/start/install.html#installation-from-docker
> - https://hub.docker.com/r/verlai/verl/tags

#### 拉取镜像

```bash
docker pull verlai/verl:vllm011.latest
```

> 保存镜像
>
> ```
> docker save -o verl.tar verlai/verl:vllm011.latest
> ```

#### 构建容器

```bash
docker create \
    --runtime=nvidia \
    --gpus all \
    --net=host \
    --shm-size="512g" \
    --cap-add=SYS_ADMIN \
    --entrypoint /bin/bash \
    -v /data/cheyujie/code/verl:/workspace/verl \
    -v /data/cheyujie/models:/models \
    -v /data/cheyujie/datasets:/datasets \
    -v /data/cheyujie/ray:/ray \
    -w /workspace/verl \
    --name verl \
    verlai/verl:vllm011.latest -c "sleep infinity"
```

- `--shm-size` 参数在宿主机执行 `df -h /dev/shm` 来确定
  - 如果只是服务推理、IO 压力量不大：4G ~ 8G 一般够用
  - 含多并发请求 / 并发 stream：推荐 10G ~ 16G
  - 1 ~ 2 卡训练：8G
  - 4 ~ 8 卡训练：16G
  - 16 张及以上：32G 或更多
- `--ulimit memlock=-1`

#### 启动容器

```bash
docker start verl
docker exec -it verl bash
```

#### 安装 verl

```bash
cd /workspace/verl
pip3 install --no-deps -e .
```

#### 数据转换

```bash
python -m examples.cheyujie.mcq_data_preprocess
```

#### 容器内测试奖励函数

```bash
curl -X POST http://127.0.0.1:8018/reward \
  -H "Content-Type: application/json" \
  -d '{
    "prompt_str": "请写一篇关于人工智能的文章。",
    "response_str": "人工智能正在改变世界。<|im_end|>",
    "model": "qwen"
}'
```

如果没启动

```bash
cd /workspace/verl/examples/external_reward
nohup python verl_rm.py  > ./rm.log 2>&1 &
```

## 训练
### 单机
#### SFT
```bash
./examples/cheyujie/sft_run_single_node.sh 2>&1 | tee -a train.log
```

#### RL
```bash
cd verl
nohup ./examples/cheyujie/rl_run_single_node.sh > ./train.log 2>&1 &
```

### 多机
#### SFT
```bash
./examples/cheyujie/sft_run_multi_node.sh 2>&1 | tee -a train.log
```

#### RL
1. 主节点: `ray start --head --dashboard-host=0.0.0.0` (运行后会提示后续操作步骤)
2. 从节点: `ray start --address=<address>`
3. 编写脚本
4. 启动训练: `./examples/cheyujie/rl_run_multi_node.sh`

### Megatron
#### RL

1. 权重转换: `python scripts/converter_hf_to_mcore.py --hf_model_path $HF_MODEL_PATH --output_path $DIST_CKPT_PATH`

2. 训练: `./examples/cheyujie/rl_run_megatron.sh`


## 合并

若未指定`trainer.default_local_dir`，默认保存位置为`checkpoints/${trainer.project_name}/${trainer.experiment_name}/global_step_1/actor`

```bash
python3 -m verl.model_merger merge \
    --backend fsdp \
    --local_dir checkpoints/${trainer.project_name}/${trainer.experiment_name}/global_step_1/actor \
    --target_dir checkpoints/${trainer.project_name}/${trainer.experiment_name}/global_step_1/actor/huggingface
```

python3 -m verl.model_merger merge \
 --backend fsdp \
 --local_dir /experiments/Qwen3-32B-202507131348/global_step_30/actor \
 --target_dir /model/Fine-tuned/Qwen3-32B

## Debug

```bash
ulimit -u 65535
```
