## 环境设置

```bash
conda create -n verl python=3.11
conda activate verl
pip install -e . -i https://mirrors.aliyun.com/pypi/simple
pip install psutil ninja msgspec vllm tensordict tensorboard nvitop -i https://mirrors.aliyun.com/pypi/simple
pip install flash-attn --no-build-isolation -i https://mirrors.aliyun.com/pypi/simple
# or
# MAX_JOBS=128 pip install flash-attn --no-build-isolation
pip install flashinfer-python
```


## 使用方式
1. 配置环境
2. `examples/data_preprocess/demo.py`把数据从`json`转换为`parquet`格式
3. 添加新写的奖励脚本`/verl/workers/reward_manager/external.py`
4. `verl/workers/reward_manager/__init__.py`添加新写的类
5. 编辑`examples/grpo_trainer/run_qwen3_8b_llm_external.sh`, `chmod +x ...`
6. `./examples/grpo_trainer/run_qwen3_8b_llm_external.sh`


## Docker
> - https://verl.readthedocs.io/en/latest/start/install.html#installation-from-docker
> - https://hub.docker.com/r/verlai/verl/tags

### 拉取镜像
```bash
docker pull verlai/verl:app-verl0.4-vllm0.8.5-mcore0.12.1
```

> 保存镜像
> ```
> docker save -o verl.tar verlai/verl:app-verl0.4-vllm0.8.5-mcore0.12.1
> ```

### 构建容器
```bash
docker create \
    --runtime=nvidia \
    --gpus all \
    --net=host \
    --shm-size="504g" \
    --cap-add=SYS_ADMIN \
    -v .:/workspace/verl \
    -v /data/cheyujie/code/all_in_one/models/huggingface:/model \
    -v /data/cheyujie/github_fork/verl/data:/data \
    -v /data/cheyujie/ray:/ray \
    --name verl \
    verlai/verl:app-verl0.4-vllm0.8.5-mcore0.12.1 \
    sleep infinity
```
- `--shm-size` 参数在宿主机执行 `df -h /dev/shm` 来确定
- `--ulimit memlock=-1`


```bash
docker start verl
docker exec -it verl bash
```

- 如果只是服务推理、IO压力量不大：4G ~ 8G 一般够用

- 含多并发请求 / 并发 stream：推荐 10G ~ 16G

- 1 ~ 2 卡训练：8G

- 4 ~ 8 卡训练：16G

- 16 张及以上：32G 或更多

### 容器内测试奖励函数
```bash
curl -X POST http://127.0.0.1:8018/reward \
  -H "Content-Type: application/json" \
  -d '{
    "prompt_str": "请写一篇关于人工智能的文章。",
    "response_str": "人工智能正在改变世界。<|im_end|>",
    "model": "qwen"
}'
```

如果没启动
```bash
cd /workspace/verl/examples/external_reward
nohup python verl_rm.py  > ./rm.log 2>&1 &
```

### 训练
```bash
cd verl
nohup ./examples/grpo_trainer/run_qwen3_32b_llm_external_in_docker.sh  > ./train.log 2>&1 &
```

### 合并
若未指定`trainer.default_local_dir`，默认保存位置为`checkpoints/${trainer.project_name}/${trainer.experiment_name}/global_step_1/actor`
```bash
python3 -m verl.model_merger merge \
    --backend fsdp \
    --local_dir checkpoints/${trainer.project_name}/${trainer.experiment_name}/global_step_1/actor \
    --target_dir checkpoints/${trainer.project_name}/${trainer.experiment_name}/global_step_1/actor/huggingface
```

python3 -m verl.model_merger merge \
    --backend fsdp \
    --local_dir /experiments/Qwen3-32B-202507131348/global_step_30/actor \
    --target_dir /model/Fine-tuned/Qwen3-32B



### Debug
```bash
ulimit -u 65535
```